{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ratnesh003/HCLTech-Tasks/blob/main/Silver%20Badge%20Assignments/Assignment%204/HCLTech_ML_Assignment_2_Task_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3E4DzMvKbgv"
      },
      "source": [
        "# Assignment 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-KW8IRZKjDV"
      },
      "source": [
        "#### create a toolchain with LLM, Lang chain and NoSQL database such as MongoDB or Redis and upload your information on to the NoSQL database and query it through an LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkGeDLvcdkA0"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiyRnO5NOiKo",
        "outputId": "a1036d19-4ec0-47f8-c714-5f801a2eb806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.2.14 in /usr/local/lib/python3.12/dist-packages (0.2.14)\n",
            "Requirement already satisfied: langchain-core==0.2.33 in /usr/local/lib/python3.12/dist-packages (0.2.33)\n",
            "Requirement already satisfied: langchain-community==0.2.12 in /usr/local/lib/python3.12/dist-packages (0.2.12)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (0.1.22)\n",
            "Collecting langchain-openai\n",
            "  Using cached langchain_openai-1.1.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.12/dist-packages (4.15.5)\n",
            "Requirement already satisfied: voyageai in /usr/local/lib/python3.12/dist-packages (0.3.3)\n",
            "Collecting voyageai\n",
            "  Using cached voyageai-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.14) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.14) (2.0.45)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.14) (3.13.2)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.14) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.14) (0.1.147)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.14) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.14) (2.12.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.14) (2.32.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.14) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.2.33) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.2.33) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.2.33) (4.15.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.2.12) (0.6.7)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-openai\n",
            "  Using cached langchain_openai-1.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-1.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-1.1.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-1.1.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-1.1.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Using cached langchain_openai-0.3.34-py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Using cached langchain_openai-0.3.32-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Using cached langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Using cached langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Using cached langchain_openai-0.3.29-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Using cached langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.27-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.26-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.25-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.24-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.23-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.22-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.21-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.20-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.19-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.18-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.17-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.15-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.13-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.11-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.3.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.3.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.1.24-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pymongo) (2.8.0)\n",
            "Requirement already satisfied: aiolimiter in /usr/local/lib/python3.12/dist-packages (from voyageai) (1.2.1)\n",
            "Collecting ffmpeg-python (from voyageai)\n",
            "  Using cached ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "INFO: pip is looking at multiple versions of voyageai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting voyageai\n",
            "  Using cached voyageai-0.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Using cached voyageai-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Using cached voyageai-0.3.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from voyageai) (11.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12) (0.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.2.33) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.14) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.14) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.14) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.2.14) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.2.14) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.2.14) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.14) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.14) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.14) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.14) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.14) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.14) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.14) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \\\n",
        "  langchain==0.2.14 \\\n",
        "  langchain-core==0.2.33 \\\n",
        "  langchain-community==0.2.12 \\\n",
        "  langchain-openai \\\n",
        "  transformers \\\n",
        "  bitsandbytes \\\n",
        "  accelerate \\\n",
        "  sentence-transformers \\\n",
        "  pymongo \\\n",
        "  voyageai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqCraRI2dpY2"
      },
      "source": [
        "### Import all required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LQvfVKVeOklD"
      },
      "outputs": [],
      "source": [
        "from pymongo import MongoClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.vectorstores import MongoDBAtlasVectorSearch\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    pipeline,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import notebook as tqdm\n",
        "\n",
        "import voyageai\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOn6NW4Kd6MV"
      },
      "source": [
        "### Connect MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK13u_rLOoYR",
        "outputId": "60580e41-4541-4dd3-cbb5-2c76f16906f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to sample_mflix.embedded_movies\n"
          ]
        }
      ],
      "source": [
        "MONGODB_URI = \"mongodb+srv://ratneshpasi03_db_user:oipChZUGbozFbvgq@cluster0.whyk18t.mongodb.net/\"\n",
        "\n",
        "client = MongoClient(MONGODB_URI)\n",
        "\n",
        "db = client[\"sample_mflix\"]\n",
        "collection = db[\"embedded_movies\"]\n",
        "\n",
        "print(\"Connected to sample_mflix.embedded_movies\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q1Ma9Y3eFI4"
      },
      "source": [
        "### save embeddings using miniLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zteq_Ch36LV7"
      },
      "outputs": [],
      "source": [
        "minilm_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minilm_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWTK8z-hxMZ3",
        "outputId": "080cf3fd-fdcf-4af2-d1e0-b8032bb59bf3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
              "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "  (2): Normalize()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0t-glbg7chl"
      },
      "outputs": [],
      "source": [
        "cursor = collection.find(\n",
        "    {\"plot_embedding_minilm\": {\"$exists\": False}},\n",
        "    {\"plot\": 1, \"fullplot\": 1}\n",
        ")\n",
        "\n",
        "skipped = 0\n",
        "updated = 0\n",
        "\n",
        "for doc in tqdm.tqdm(cursor):\n",
        "    text = doc.get(\"fullplot\") or doc.get(\"plot\")\n",
        "\n",
        "    if not text:\n",
        "        skipped += 1\n",
        "        continue\n",
        "\n",
        "    embedding = minilm_model.encode(text).tolist()\n",
        "\n",
        "    collection.update_one(\n",
        "        {\"_id\": doc[\"_id\"]},\n",
        "        {\"$set\": {\"plot_embedding_minilm\": embedding}}\n",
        "    )\n",
        "    updated += 1\n",
        "\n",
        "print(f\"Updated: {updated}, Skipped (no text): {skipped}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reX44m6weQti"
      },
      "source": [
        "### Initialize Generation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iV79PWXnQsZU"
      },
      "outputs": [],
      "source": [
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# 4-bit quantization config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")\n",
        "\n",
        "# Model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",          # REQUIRED for 4-bit\n",
        "    quantization_config=bnb_config,\n",
        "    torch_dtype=torch.float16   # compute dtype\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4tbmszuxGU4",
        "outputId": "97468d0f-5a2a-42f0-b47f-44774deb9067"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MistralForCausalLM(\n",
              "  (model): MistralModel(\n",
              "    (embed_tokens): Embedding(32000, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x MistralDecoderLayer(\n",
              "        (self_attn): MistralAttention(\n",
              "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): MistralMLP(\n",
              "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLUActivation()\n",
              "        )\n",
              "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "    (rotary_emb): MistralRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn3PjA88etkx"
      },
      "source": [
        "### Helper functions for retrival from mongo vector db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0Ts3xGrFRAnM"
      },
      "outputs": [],
      "source": [
        "def vector_search(embedding, field_name):\n",
        "    pipeline = [\n",
        "        {\n",
        "            \"$vectorSearch\": {\n",
        "                \"index\": \"movie_plot_vector_index\",\n",
        "                \"path\": field_name,\n",
        "                \"queryVector\": embedding,\n",
        "                \"numCandidates\": 100,\n",
        "                \"limit\": 5\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"$project\": {\n",
        "                \"_id\": 0,\n",
        "                \"title\": 1,\n",
        "                \"plot\": 1,\n",
        "                \"score\": {\"$meta\": \"vectorSearchScore\"}\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "    return list(collection.aggregate(pipeline))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aiBxv3oje9Je"
      },
      "outputs": [],
      "source": [
        "def build_context(docs):\n",
        "    return \"\\n\\n\".join(\n",
        "        [f\"Title: {d['title']}\\nPlot: {d['plot']}\" for d in docs]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkNRL5_penSQ"
      },
      "source": [
        "### Create the query embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BhLOnWE5RTFK"
      },
      "outputs": [],
      "source": [
        "query = \"Which movies involve violent gangsters or organized crime?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DUdIw6BFRQPd"
      },
      "outputs": [],
      "source": [
        "voyage_client = voyageai.Client(api_key=userdata.get('VOYAGE_AI'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qgO82AeCRKVt"
      },
      "outputs": [],
      "source": [
        "query_embedding_voyage_large_2 = voyage_client.embed(\n",
        "    texts=[query],\n",
        "    model=\"voyage-large-2\",\n",
        ").embeddings[0]\n",
        "\n",
        "query_embedding_voyage_large_3 = voyage_client.embed(\n",
        "    texts=[query],\n",
        "    model=\"voyage-3-large\",\n",
        "    output_dimension=2048\n",
        ").embeddings[0]\n",
        "\n",
        "query_embedding_minilm = minilm_model.encode(query).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wPmMMTqfKvi"
      },
      "source": [
        "### Helper function for Generating responeses using Mistral model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "X5l1akbndFcp"
      },
      "outputs": [],
      "source": [
        "def format_mistral_prompt(context, query, label):\n",
        "    return f\"\"\"[INST]\n",
        "You are a movie recommendation assistant.\n",
        "\n",
        "Answer the question naturally and confidently.\n",
        "Do not mention sources, documents, context, or embeddings.\n",
        "Do not say things like \"based on the context\" or \"from the information provided\".\n",
        "If the information is insufficient, say that you do not have enough information.\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Information:\n",
        "{context}\n",
        "[/INST]\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4YhvnRFZdGZ2"
      },
      "outputs": [],
      "source": [
        "def generate_answer_mistral(context, label):\n",
        "    prompt = format_mistral_prompt(context, query, label)\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=4096\n",
        "    ).to(model.device)\n",
        "\n",
        "    prompt_length = inputs[\"input_ids\"].shape[1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=350,\n",
        "            do_sample=True,\n",
        "            temperature=0.4,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.1\n",
        "        )\n",
        "\n",
        "    # Slice off the prompt tokens\n",
        "    generated_tokens = outputs[0][prompt_length:]\n",
        "\n",
        "    decoded = tokenizer.decode(\n",
        "        generated_tokens,\n",
        "        skip_special_tokens=True\n",
        "    ).strip()\n",
        "\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0A9O0dIfbSa"
      },
      "source": [
        "### Retrival and Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FJ18FTcLfb0X"
      },
      "outputs": [],
      "source": [
        "docs_voyage_large_2 = vector_search(query_embedding_voyage_large_2, \"plot_embedding\")\n",
        "docs_voyage_large_3 = vector_search(query_embedding_voyage_large_3, \"plot_embedding_voyage_3_large\")\n",
        "docs_minilm = vector_search(query_embedding_minilm, \"plot_embedding_minilm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4uHIDHB-fscl"
      },
      "outputs": [],
      "source": [
        "context_voyage_large_2 = build_context(docs_voyage_large_2)\n",
        "context_voyage_large_3 = build_context(docs_voyage_large_3)\n",
        "context_minilm = build_context(docs_minilm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmK-M_sef1X7",
        "outputId": "51da90f1-5bea-4479-a1e2-6d8ea5bdf6d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "answer_voyage_large_2 = generate_answer_mistral(context_voyage_large_2, \"Voyage-Large-2\")\n",
        "answer_voyage_large_3 = generate_answer_mistral(context_voyage_large_3, \"Voyage-3-Large\")\n",
        "answer_minilm = generate_answer_mistral(context_minilm, \"MiniLM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbswWxNMf3kE",
        "outputId": "ec5d679d-c743-4b1f-c9bd-1469acdb4322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "VOYAGE-LARGE-2 — Retrieved Documents\n",
            "====================================================================================================\n",
            "Title: Ghost\n",
            "Plot: After an accident leaves a young man dead, his spirit stays behind to warn his lover of impending danger, with the help of a reluctant psychic.\n",
            "\n",
            "Title: Imaginaerum\n",
            "Plot: A coma sends an old man into his childhood's sinister fantasy world, where he must fight dementia and gain back his memories before it's too late.\n",
            "\n",
            "Title: Riddick\n",
            "Plot: Left for dead on a sun-scorched planet, Riddick finds himself up against an alien race of predators. Activating an emergency beacon alerts two ships: one carrying a new breed of mercenary, the other captained by a man from Riddick's past.\n",
            "\n",
            "Title: Dead Man\n",
            "Plot: On the run after murdering a man, accountant William Blake encounters a strange North American man named Nobody who prepares him for his journey into the spiritual world.\n",
            "\n",
            "Title: JLA Adventures: Trapped in Time\n",
            "Plot: Lex Luthor is frozen during a battle with the Justice League. He thaws out in the 31st century, discovers Time Trapper and prevents Superman's arrival to Earth as a baby. Future teen heroes Karate Kid and Dawnstar must stop him.\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "VOYAGE — Generated Answer (Mistral)\n",
            "====================================================================================================\n",
            "Among the given titles, \"Riddick\" and \"JLA Adventures: Trapped in Time\" involve violent elements related to gangsters or organized crime. In \"Riddick,\" Riddick is hunted by mercenaries and an alien race, while in \"JLA Adventures: Trapped in Time,\" Lex Luthor, a criminal mastermind, attempts to alter history and prevent the arrival of Superman.\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "VOYAGE — Retrieved Documents\n",
            "====================================================================================================\n",
            "Title: Scarface\n",
            "Plot: An ambitious and near insanely violent gangster climbs the ladder of success in the mob, but his weaknesses prove to be his downfall.\n",
            "\n",
            "Title: Flash Point\n",
            "Plot: A hot-headed inspector takes on a small but powerful Vietnamese-Chinese gang, after a series of crimes and murder attempts committed and putting an undercover cop and his girlfriend in great danger.\n",
            "\n",
            "Title: Flash Point\n",
            "Plot: A hot-headed inspector takes on a small but powerful Vietnamese-Chinese gang, after a series of crimes and murder attempts committed and putting an undercover cop and his girlfriend in great danger.\n",
            "\n",
            "Title: Rough Cut\n",
            "Plot: A gangster who wants to be an actor; an actor more gangster than anything. Here their paths and lives begin to cross.\n",
            "\n",
            "Title: State Property 2\n",
            "Plot: Three gangsters vie for control of the streets of Philadelphia.\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "VOYAGE — Generated Answer (Mistral)\n",
            "====================================================================================================\n",
            "Based on the given plot summaries, the following movies involve violent gangsters or organized crime:\n",
            "\n",
            "Scarface: This movie follows an ambitious and violent gangster as he rises through the ranks of the mob.\n",
            "\n",
            "Flash Point (2007): In this film, a hot-headed inspector goes up against a dangerous Vietnamese-Chinese gang responsible for a series of crimes and endangering an undercover cop and his girlfriend.\n",
            "\n",
            "State Property 2: The plot revolves around three gangsters competing for control of the streets of Philadelphia.\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "MINILM — Retrieved Documents\n",
            "====================================================================================================\n",
            "Title: A Most Violent Year\n",
            "Plot: In New York City 1981, an ambitious immigrant fights to protect his business and family during the most dangerous year in the city's history.\n",
            "\n",
            "Title: Better Mus Come\n",
            "Plot: The film follows warring political factions in 1970s Jamaica as they enlist the support of gangs to enforce their policies, and advance their political agenda. It is a fictionalized ...\n",
            "\n",
            "Title: Shanghai Express\n",
            "Plot: Multi-genre flick (western, martial arts, comedy, adventure, etc.) with an all-star cast about a man who returns to his home town, buys everything in sight, and tries to improve its ...\n",
            "\n",
            "Title: Grindhouse\n",
            "Plot: Quentin Tarantino and Rober Rodriguez's homage to drive-in double features in the 60s and 70s with two back-to-back cult films that include previews of coming attractions between them.\n",
            "\n",
            "Title: The Great Train Robbery\n",
            "Plot: A group of bandits stage a brazen train hold-up, only to find a determined posse hot on their heels.\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "MINILM — Generated Answer (Mistral)\n",
            "====================================================================================================\n",
            "Based on the plot descriptions you've given, the following movies involve violent gangsters or organized crime:\n",
            "\n",
            "* A Most Violent Year: While the focus is on an immigrant protecting his business and family, the setting is during one of the most violent years in New York City's history, implying the presence of violent gangsters and organized crime.\n",
            "* Better Mus Come: This movie revolves around warring political factions in Jamaica who enlist the support of gangs to enforce their policies and advance their political agenda.\n",
            "* The Great Train Robbery: Although not explicitly stated, the title itself suggests a criminal act involving a large group of people planning and executing a train robbery.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def print_block(title, content):\n",
        "    print(\"=\" * 100)\n",
        "    print(title)\n",
        "    print(\"=\" * 100)\n",
        "    print(content)\n",
        "    print(\"\\n\")\n",
        "\n",
        "print_block(\"VOYAGE-LARGE-2 — Retrieved Documents\", context_voyage_large_2)\n",
        "print_block(\"VOYAGE — Generated Answer (Mistral)\", answer_voyage_large_2)\n",
        "\n",
        "print_block(\"VOYAGE — Retrieved Documents\", context_voyage_large_3)\n",
        "print_block(\"VOYAGE — Generated Answer (Mistral)\", answer_voyage_large_3)\n",
        "\n",
        "print_block(\"MINILM — Retrieved Documents\", context_minilm)\n",
        "print_block(\"MINILM — Generated Answer (Mistral)\", answer_minilm)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vHkkrNcPqehm"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNmBa2WPxpZhqVjpRr1Lx3z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}